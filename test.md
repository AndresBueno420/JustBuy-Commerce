# **Entrega 3 - Sistema de Reconocimiento de Actividades en Video (Video Activity Recognition)**

### **Selecci√≥n de Caracter√≠sticas, Modelo Final SVM Reducido y Despliegue en Tiempo Real**

## **1. Introducci√≥n**

En esta tercera entrega se integran todos los componentes desarrollados en el proyecto para construir un **sistema completo de reconocimiento de actividades humanas (HAR) en tiempo real**, basado en visi√≥n por computador y aprendizaje autom√°tico.

Los avances principales incluyen:

- Reducci√≥n optimizada de caracter√≠sticas mediante **SelectKBest (ANOVA F-score)**.  

- Entrenamiento de un **SVM reducido con 70 caracter√≠sticas**, seleccionadas desde ~140 originales.  

- Integraci√≥n del modelo reducido en un **pipeline de inferencia en tiempo real**.  

- Construcci√≥n de una **interfaz visual (UI)** con informaci√≥n biomec√°nica complementaria.  

- Despliegue multiplataforma mediante **ejecutable en Windows** y **Docker para Linux/Mac**.  

Este README documenta la arquitectura del sistema, la metodolog√≠a empleada, los resultados obtenidos y las instrucciones de despliegue.

## ** 2. Objetivos de la Entrega 3**

- Seleccionar un subconjunto √≥ptimo de caracter√≠sticas que maximice el rendimiento del modelo.  

- Entrenar y validar un modelo reducido que mantenga (o supere) el desempe√±o del modelo completo.  

- Integrar el modelo reducido en el sistema de inferencia.  

- Construir la aplicaci√≥n final en tiempo real con:  
  - Predicci√≥n de actividad.  

  - Probabilidad asociada.  

  - M√©tricas posturales (inclinaci√≥n, √°ngulos de rodilla).  

  - Paneles superpuestos en video.  

- Desplegar el sistema en forma de:  
  - Ejecutable (.exe) para Windows.  

  - Imagen Docker para Linux/Mac.  

- Documentar limitaciones, mejoras logradas y l√≠neas de trabajo futuro.  

## ** 3. Metodolog√≠a de selecci√≥n de caracter√≠sticas (Entrega 3)**

En el notebook 01_svm_feature_reduction.ipynb se realiz√≥ el proceso sistem√°tico de selecci√≥n de caracter√≠sticas:

### **üîπ 3.1. Dataset utilizado**

Se emple√≥ el features.csv de la Entrega 2, que contiene:

- Todas las caracter√≠sticas extra√≠das por ventana temporal.  

- Labels (actividades).  

- Identificadores de video para hacer particiones estratificadas.  

### **üîπ 3.2. Split estratificado por video (GroupShuffleSplit)**

Evita leakage temporal entre frames consecutivos del mismo video.

### **üîπ 3.3. Entrenamiento base**

Se entren√≥ un SVM con todas las caracter√≠sticas para obtener una l√≠nea base.

### **üîπ 3.4. Selecci√≥n de caracter√≠sticas**

Se evaluaron variantes con:

K ‚àà {15, 30, 60, 70, 80, 90, 100}

Cada modelo consisti√≥ en:

Pipeline = \[SelectKBest(f_classif, k=K) ‚Üí StandardScaler ‚Üí SVM (RBF)\]

### **üîπ 3.5. Resultados**

**Mejor modelo reducido:  
<br/>**K = 70

F1-macro = 0.887

- **Total de features seleccionadas:** 70  

**Primeras 10 features m√°s relevantes:  
<br/>**\['knee_left_mean', 'knee_left_std', 'knee_right_mean',

'knee_right_std', 'hip_left_mean', 'hip_left_std',

'hip_right_mean', 'hip_right_std', 'inclination_std',

'vel_left_hip_mean'\]

### **üîπ Archivos generados**

- svm_reduced.joblib - mejor modelo reducido.  

- selected_features.json - lista de caracter√≠sticas seleccionadas.  

- feature_reduction_summary.md - resumen textual de resultados.  

## ** 4. Principales descubrimientos (basado en log1 y log2)**

### **‚úî Mejoras logradas gracias al muestreo correcto (cada 6 frames)**

- El sistema ahora replica exactamente el muestreo usado en entrenamiento.  

- **Significativa mejora** en las actividades:  
  - Sentarse  

  - Pararse  

### **‚úî Estabilidad general**

- Actividades con patrones claros (caminar, caminar hacia atr√°s, desplazamientos) funcionan con estabilidad.  

### **‚úî Limitaciones actuales**

- **Girar (rotate)** permanece como la actividad m√°s dif√≠cil:  
  - Variabilidad rotacional alta.  

  - Baja visibilidad de landmarks en giros r√°pidos.  

  - Falta de features basadas en orientaci√≥n y rotaci√≥n axial.  

## ** 5. Arquitectura del sistema en tiempo real**

El sistema est√° constituido por 3 componentes principales:

### ** 5.1. Predictor temporal (realtime_inference.py)**

Encargado de:

- Buffer temporal de frames (deque).  

Muestreo:  
<br/>frame_sample_every = 6

C√°lculo del **FPS efectivo**:  
<br/>effective_fps = fps / 6

- Ensamblaje de ventanas temporales.  

Generaci√≥n del vector de caracter√≠sticas v√≠a:  
<br/>frames_to_feature_vector(...)

- Inferencia con:  
  - SVM reducido si existe.  

  - Fallback al SVM full si falta el reducido.  

### ** L√≥gica de predicci√≥n**

M√≠nimo de frames requeridos para predecir:  
<br/>min_frames = effective_fps √ó WINDOW_SIZE_SEC

- Se emplea predict_proba (si disponible) o softmax sobre decision_function.  

Salida:  
<br/>(label_predicha, probabilidad)

### ** 5.2. M√©tricas posturales (posture_metrics.py)**

Calculadas en tiempo real:

- trunk_inclination_deg  
    Inclinaci√≥n del tronco respecto a la vertical.  

- knee_angle_l_deg  

- knee_angle_r_deg  

Son mostradas en la UI para enriquecer el sistema.

### ** 5.3. Interfaz visual (UI)**

La UI (ui_app.py) muestra:

#### **Panel 1 (informaci√≥n del modelo)**

- Variante utilizada (reduced/full).  

- FPS estimado.  

- Visibilidad media.  

- Advertencia si visibilidad < VISIBILITY_MIN.  

#### **Panel 2 (actividad)**

- Actividad predicha.  

- Probabilidad asociada.  

- C√≥digo de color:  
  - Verde ‚Üí conf. > 70%  

  - Amarillo ‚Üí 40-70%  

  - Rojo ‚Üí < 40%  

#### **Panel 3 (m√©tricas posturales)**

#### **Control de salida:**

Presiona 'q' para salir

## ** 6. Despliegue del sistema**

### ** 6.1. Ejecutable para Windows**

Construido con PyInstaller:

- Script principal: app_entry.py.  

Comando principal ejecuta:  
<br/>run_realtime_app(camera_index=0)

- Manejo de errores robusto:  
  - Si falla, genera error_log.txt.  

### ** 6.2. Imagen Docker (Linux/Mac)**

Caracter√≠sticas del contenedor:

- Basado en python:3.11-slim.  

- Incluye:  
  - OpenCV  

  - MediaPipe  

  - scikit-learn  

  - Numpy, Pandas  

Expone la aplicaci√≥n mediante:  
<br/>python -m Entrega3.src.online.ui_app

Permite ejecutar en entornos Linux sin necesidad de instalar dependencias.

## ** 7. Resultados en tiempo real**

### **‚úî Actividades que funcionan muy bien**

- Caminar adelante / atr√°s  

- Movimiento lateral  

- Posturas est√°ticas  

- Pararse / sentarse (mejorado en Entrega 3)  

### **‚úî Actividades con desempe√±o moderado**

- Girar  
    (por poca visibilidad y falta de features especializadas)  

### **‚úî M√©tricas reportadas en UI**

- Inclinaci√≥n del tronco (¬∞)  

- Angulo de rodilla izquierda (¬∞)  

- Angulo de rodilla derecha (¬∞)  

- Probabilidad de la actividad  

### **‚úî Estabilidad**

- La inferencia es fluida gracias al muestreo reducido.  

- El pipeline es consistente con el entrenamiento ‚Üí principal mejora.  

## ** 8. Limitaciones y trabajo futuro**

### ** Limitaciones**

- Actividad "girar" sigue siendo la de menor precisi√≥n.  

- El sistema depende fuertemente de visibilidad:  
  - luz adecuada  

  - ausencia de oclusiones  

  - distancia √≥ptima de la c√°mara

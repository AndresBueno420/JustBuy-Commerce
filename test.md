# **Entrega 3 - Sistema de Reconocimiento de Actividades en Video (Video Activity Recognition)**

### **SelecciÃ³n de CaracterÃ­sticas, Modelo Final SVM Reducido y Despliegue en Tiempo Real**

## **ğŸ“Œ 1. IntroducciÃ³n**

En esta tercera entrega se integran todos los componentes desarrollados en el proyecto para construir un **sistema completo de reconocimiento de actividades humanas (HAR) en tiempo real**, basado en visiÃ³n por computador y aprendizaje automÃ¡tico.

Los avances principales incluyen:

- ReducciÃ³n optimizada de caracterÃ­sticas mediante **SelectKBest (ANOVA F-score)**.  

- Entrenamiento de un **SVM reducido con 70 caracterÃ­sticas**, seleccionadas desde ~140 originales.  

- IntegraciÃ³n del modelo reducido en un **pipeline de inferencia en tiempo real**.  

- ConstrucciÃ³n de una **interfaz visual (UI)** con informaciÃ³n biomecÃ¡nica complementaria.  

- Despliegue multiplataforma mediante **ejecutable en Windows** y **Docker para Linux/Mac**.  

Este README documenta la arquitectura del sistema, la metodologÃ­a empleada, los resultados obtenidos y las instrucciones de despliegue.

## **ğŸ“Œ 2. Objetivos de la Entrega 3**

- Seleccionar un subconjunto Ã³ptimo de caracterÃ­sticas que maximice el rendimiento del modelo.  

- Entrenar y validar un modelo reducido que mantenga (o supere) el desempeÃ±o del modelo completo.  

- Integrar el modelo reducido en el sistema de inferencia.  

- Construir la aplicaciÃ³n final en tiempo real con:  
  - PredicciÃ³n de actividad.  

  - Probabilidad asociada.  

  - MÃ©tricas posturales (inclinaciÃ³n, Ã¡ngulos de rodilla).  

  - Paneles superpuestos en video.  

- Desplegar el sistema en forma de:  
  - Ejecutable (.exe) para Windows.  

  - Imagen Docker para Linux/Mac.  

- Documentar limitaciones, mejoras logradas y lÃ­neas de trabajo futuro.  

## **ğŸ“Œ 3. MetodologÃ­a de selecciÃ³n de caracterÃ­sticas (Entrega 3)**

En el notebook 01_svm_feature_reduction.ipynb se realizÃ³ el proceso sistemÃ¡tico de selecciÃ³n de caracterÃ­sticas:

### **ğŸ”¹ 3.1. Dataset utilizado**

Se empleÃ³ el features.csv de la Entrega 2, que contiene:

- Todas las caracterÃ­sticas extraÃ­das por ventana temporal.  

- Labels (actividades).  

- Identificadores de video para hacer particiones estratificadas.  

### **ğŸ”¹ 3.2. Split estratificado por video (GroupShuffleSplit)**

Evita leakage temporal entre frames consecutivos del mismo video.

### **ğŸ”¹ 3.3. Entrenamiento base**

Se entrenÃ³ un SVM con todas las caracterÃ­sticas para obtener una lÃ­nea base.

### **ğŸ”¹ 3.4. SelecciÃ³n de caracterÃ­sticas**

Se evaluaron variantes con:

K âˆˆ {15, 30, 60, 70, 80, 90, 100}

Cada modelo consistiÃ³ en:

Pipeline = \[SelectKBest(f_classif, k=K) â†’ StandardScaler â†’ SVM (RBF)\]

### **ğŸ”¹ 3.5. Resultados**

**Mejor modelo reducido:  
<br/>**K = 70

F1-macro = 0.887

- **Total de features seleccionadas:** 70  

**Primeras 10 features mÃ¡s relevantes:  
<br/>**\['knee_left_mean', 'knee_left_std', 'knee_right_mean',

'knee_right_std', 'hip_left_mean', 'hip_left_std',

'hip_right_mean', 'hip_right_std', 'inclination_std',

'vel_left_hip_mean'\]

### **ğŸ”¹ Archivos generados**

- svm_reduced.joblib - mejor modelo reducido.  

- selected_features.json - lista de caracterÃ­sticas seleccionadas.  

- feature_reduction_summary.md - resumen textual de resultados.  

## **ğŸ“Œ 4. Principales descubrimientos (basado en log1 y log2)**

### **âœ” Mejoras logradas gracias al muestreo correcto (cada 6 frames)**

- El sistema ahora replica exactamente el muestreo usado en entrenamiento.  

- **Significativa mejora** en las actividades:  
  - Sentarse  

  - Pararse  

### **âœ” Estabilidad general**

- Actividades con patrones claros (caminar, caminar hacia atrÃ¡s, desplazamientos) funcionan con estabilidad.  

### **âœ” Limitaciones actuales**

- **Girar (rotate)** permanece como la actividad mÃ¡s difÃ­cil:  
  - Variabilidad rotacional alta.  

  - Baja visibilidad de landmarks en giros rÃ¡pidos.  

  - Falta de features basadas en orientaciÃ³n y rotaciÃ³n axial.  

## **ğŸ“Œ 5. Arquitectura del sistema en tiempo real**

El sistema estÃ¡ constituido por 3 componentes principales:

### **ğŸ”¹ 5.1. Predictor temporal (realtime_inference.py)**

Encargado de:

- Buffer temporal de frames (deque).  

Muestreo:  
<br/>frame_sample_every = 6

CÃ¡lculo del **FPS efectivo**:  
<br/>effective_fps = fps / 6

- Ensamblaje de ventanas temporales.  

GeneraciÃ³n del vector de caracterÃ­sticas vÃ­a:  
<br/>frames_to_feature_vector(...)

- Inferencia con:  
  - SVM reducido si existe.  

  - Fallback al SVM full si falta el reducido.  

### **ğŸ§  LÃ³gica de predicciÃ³n**

MÃ­nimo de frames requeridos para predecir:  
<br/>min_frames = effective_fps Ã— WINDOW_SIZE_SEC

- Se emplea predict_proba (si disponible) o softmax sobre decision_function.  

Salida:  
<br/>(label_predicha, probabilidad)

### **ğŸ”¹ 5.2. MÃ©tricas posturales (posture_metrics.py)**

Calculadas en tiempo real:

- trunk_inclination_deg  
    InclinaciÃ³n del tronco respecto a la vertical.  

- knee_angle_l_deg  

- knee_angle_r_deg  

Son mostradas en la UI para enriquecer el sistema.

### **ğŸ”¹ 5.3. Interfaz visual (UI)**

La UI (ui_app.py) muestra:

#### **Panel 1 (informaciÃ³n del modelo)**

- Variante utilizada (reduced/full).  

- FPS estimado.  

- Visibilidad media.  

- Advertencia si visibilidad < VISIBILITY_MIN.  

#### **Panel 2 (actividad)**

- Actividad predicha.  

- Probabilidad asociada.  

- CÃ³digo de color:  
  - Verde â†’ conf. > 70%  

  - Amarillo â†’ 40-70%  

  - Rojo â†’ < 40%  

#### **Panel 3 (mÃ©tricas posturales)**

#### **Control de salida:**

Presiona 'q' para salir

## **ğŸ“Œ 6. Despliegue del sistema**

### **ğŸ”¹ 6.1. Ejecutable para Windows**

Construido con PyInstaller:

- Script principal: app_entry.py.  

Comando principal ejecuta:  
<br/>run_realtime_app(camera_index=0)

- Manejo de errores robusto:  
  - Si falla, genera error_log.txt.  

### **ğŸ”¹ 6.2. Imagen Docker (Linux/Mac)**

CaracterÃ­sticas del contenedor:

- Basado en python:3.11-slim.  

- Incluye:  
  - OpenCV  

  - MediaPipe  

  - scikit-learn  

  - Numpy, Pandas  

Expone la aplicaciÃ³n mediante:  
<br/>python -m Entrega3.src.online.ui_app

Permite ejecutar en entornos Linux sin necesidad de instalar dependencias.

## **ğŸ“Œ 7. Resultados en tiempo real**

### **âœ” Actividades que funcionan muy bien**

- Caminar adelante / atrÃ¡s  

- Movimiento lateral  

- Posturas estÃ¡ticas  

- Pararse / sentarse (mejorado en Entrega 3)  

### **âœ” Actividades con desempeÃ±o moderado**

- Girar  
    (por poca visibilidad y falta de features especializadas)  

### **âœ” MÃ©tricas reportadas en UI**

- InclinaciÃ³n del tronco (Â°)  

- Angulo de rodilla izquierda (Â°)  

- Angulo de rodilla derecha (Â°)  

- Probabilidad de la actividad  

### **âœ” Estabilidad**

- La inferencia es fluida gracias al muestreo reducido.  

- El pipeline es consistente con el entrenamiento â†’ principal mejora.  

## ** 8. Limitaciones y trabajo futuro**

### ** Limitaciones**

- Actividad "girar" sigue siendo la de menor precisiÃ³n.  

- El sistema depende fuertemente de visibilidad:  
  - luz adecuada  

  - ausencia de oclusiones  

  - distancia Ã³ptima de la cÃ¡mara
